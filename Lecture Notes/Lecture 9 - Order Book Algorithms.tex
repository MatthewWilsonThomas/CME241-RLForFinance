\documentclass[11pt]{article}

% Load package
\usepackage{lesson}

% Set title and course name
\settitle{Lecture 9}
\setsubtitle{Limit Order Book Algorithms}
\setcourse{CME241 - Reinforcement Learning for Finance}
\setdate{08.02.2023}

\begin{document}

% Create title and add proper header for first page
\maketitle
\thispagestyle{first}
We have the trading Order Book with the standard market terminology accompanying this. 

We have standard Order Book activity, including:
\begin{itemize}
    \item Sell LO (potentially removes best bid)
    \item Buy LO (potentially removes best sell)
    \item Sell Market Order (will removes best bid)
    \item Buy Market Order (will removes best sell)
\end{itemize}

Price Impact of a Market Order is the amount that a market order moves the Spread. Subsequent activity is part of the Order Book (OB) Dynamics.

\section{Optimal Trade Execution}
\paragraph*{Problem Statement}
Time steps indexed by $t=0,1, \ldots, T$.
$P_t$ denotes Best Bid Price at start of time step $t$.
$N_t$ denotes number of shares sold in time step $t$.
$R_t=N-\sum_{i=0}^{t-1} N_i=$ shares remaining to be sold at start of time step $t$.
Note that $R_0=N, R_{t+1}=R_t-N_t$ for all $t<T, N_{T-1}=R_{T-1} \Rightarrow R_T=0$.
Price Dynamics given by:
$$
P_{t+1}=f_t\left(P_t, N_t, \epsilon_t\right)
$$
where $f_t(\cdot)$ is an arbitrary function incorporating:
\begin{itemize}
    \item Permanent Price Impact of selling $N_t$ shares.
    \item Impact-independent market-movement of Best Bid Price for time step $t$
    \item $\epsilon_t$ denotes source of randomness in Best Bid Price 
\end{itemize}market-movement
Sales Proceeds in time step $t$ defined as:
$$
N_t \cdot Q_t=N_t \cdot\left(P_t-g_t\left(P_t, N_t\right)\right)
$$
where $g_t(\cdot)$ is an arbitrary func representing Temporary Price Impact Utility of Sales Proceeds function denoted as $U(\cdot)$.

\paragraph*{MDP Formulation}
This is a discrete-time, finite-horizon MDP.
MDP Horizon is time $T$, meaning all states at time $T$ are terminal.
Order of MDP activity in each time step $0 \leq t<T$ :
\begin{itemize}
    \item Observe State $s_t:=\left(P_t, R_t\right) \in \mathcal{S}_t$
    \item Perform Action $a_t:=N_t \in \mathcal{A}_t$
    \item Receive Reward $r_{t+1}:=U\left(N_t \cdot Q_t\right)=U\left(N_t \cdot\left(P_t-g_t\left(P_t, N_t\right)\right)\right)$
    \item Experience Price Dynamics $P_{t+1}=f_t\left(P_t, N_t, \epsilon_t\right)$
\end{itemize}
Goal is to find a Policy $\pi_t^*\left(\left(P_t, R_t\right)\right)=N_t^*$ that maximizes:
$$
\mathbb{E}\left[\sum_{t=0}^{T-1} \gamma^t \cdot U\left(N_t \cdot Q_t\right)\right]
$$ where $\gamma$ is MDP discount factor.

\paragraph*{Model}
We then have simple linear model with Linear Price Impact. We have i.i.d randomness with price dynamics $P_{t+1} = P_t - \alpha N_t + \epsilon_t$. Permanent price impact of $\alpha N_t$ and temporary price impact of $\beta N_t$. 

\paragraph*{Solution}
We can solve this model using Optimal Value Functions and the Bellman Equation. 
Denote Value Function for policy $\pi$ as:
$$
V_t^\pi\left(\left(P_t, R_t\right)\right)=\mathbb{E}_\pi\left[\sum_{i=t}^T N_i\left(P_i-\beta \cdot N_i\right) \mid\left(P_t, R_t\right)\right]
$$
Denote Optimal Value Function as $V_t^*\left(\left(P_t, R_t\right)\right)=\max _\pi V_t^\pi\left(\left(P_t, R_t\right)\right)$
Optimal Value Function satisfies the Bellman Eqn $(\forall 0 \leq t<T-1)$ :
$$
\begin{gathered}
V_t^*\left(\left(P_t, R_t\right)\right)=\max _{N_t}\left\{N_t \cdot\left(P_t-\beta \cdot N_t\right)+\mathbb{E}\left[V_{t+1}^*\left(\left(P_{t+1}, R_{t+1}\right)\right)\right]\right\} \\
V_{T-1}^*\left(\left(P_{T-1}, R_{T-1}\right)\right)=N_{T-1} \cdot\left(P_{T-1}-\beta \cdot N_{T-1}\right)=R_{T-1} \cdot\left(P_{T-1}-\beta \cdot R_{T-1}\right)
\end{gathered}
$$
From the above, we can infer $V_{T-2}^*\left(\left(P_{T-2}, R_{T-2}\right)\right)$ as:
$$
\begin{gathered}
\max _{N_{T-2}}\left\{N_{T-2}\left(P_{T-2}-\beta N_{T-2}\right)+\mathbb{E}\left[R_{T-1}\left(P_{T-1}-\beta R_{T-1}\right)\right]\right\} \\
=\max _{N_{T-2}}\left\{N_{T-2}\left(P_{T-2}-\beta N_{T-2}\right)+\mathbb{E}\left[\left(R_{T-2}-N_{T-2}\right)\left(P_{T-1}-\beta\left(R_{T-2}-N_{T-2}\right)\right)\right]\right\}
\end{gathered}
$$
$$
=\max _{N_{T-2}}\left\{R_{T-2} P_{T-2}-\beta R_{T-2}^2+(\alpha-2 \beta)\left(N_{T-2}^2-N_{T-2} R_{T-2}\right)\right\}
$$
For the case $\alpha \geq 2 \beta$, we have the trivial solution: $N_{T-2}^*=0$ or $R_{T-2}$ Substitute $N_{T-2}^*$ in the expression for $V_{T-2}^*\left(\left(P_{T-2}, R_{T-2}\right)\right)$ :
$$
V_{T-2}^*\left(\left(P_{T-2}, R_{T-2}\right)\right)=R_{T-2}\left(P_{T-2}-\beta R_{T-2}\right)
$$
Continuing backwards in time in this manner gives:
$$
\begin{gathered}
N_t^*=0 \text { or } R_t \\
V_t^*\left(\left(P_t, R_t\right)\right)=R_t\left(P_t-\beta R_t\right)
\end{gathered}
$$
So the solution for the case $\alpha \geq 2 \beta$ is to sell all $N$ shares at any one of the time steps $t=0, \ldots, T-1$ (and none in the other time steps) and the Optimal Expected Total Sale Proceeds $=N\left(P_0-\beta N\right)$
For the case $\alpha<2 \beta$, differentiating w.r.t. $N_{T-2}$ and setting to 0 gives:
$$
(\alpha-2 \beta)\left(2 N_{T-2}^*-R_{T-2}\right)=0 \Rightarrow N_{T-2}^*=\frac{R_{T-2}}{2}
$$
Substitute $N_{T-2}^*$ in the expression for $V_{T-2}^*\left(\left(P_{T-2}, R_{T-2}\right)\right.$ :
$$
V_{T-2}^*\left(\left(P_{T-2}, R_{T-2}\right)\right)=R_{T-2} P_{T-2}-R_{T-2}^2\left(\frac{\alpha+2 \beta}{4}\right)
$$
Continuing backwards in time in this manner gives:
$$
\begin{gathered}
N_t^*=\frac{R_t}{T-t} \\
V_t^*\left(\left(P_t, R_t\right)\right)=R_t P_t-\frac{R_t^2}{2}\left(\frac{2 \beta+\alpha(T-t-1)}{T-t}\right)
\end{gathered}
$$

We can see that going forward we ahve the optimal $N^*_t = \frac{N}{T}$ i.e. uniform over time. It makes sense since we had Price Impact and Market movement being linear and additive, i.e. they don't interact. 
This is equivalent to minimizing $\sum_{t=1}^T N^2_t$. 
This gives us the Optimal Expected Total Sale Proceeds as $NP_0 - \frac{N^2}{2}(\alpha + \frac{2\beta - \alpha}{T})$ i.e. an implementation shortfall of $\frac{N^2}{2}(\alpha + \frac{2\beta - \alpha}{T})$

\paragraph*{Second Model (Bertsimas-Lo)}
Bertsimas-Lo was the first paper on Optimal Trade Order Execution They assumed no risk-aversion, i.e. identity Utility function The first model in their paper is a special case of our simple Linear Impact model, with fully Permanent Impact (i.e., $\alpha=\beta$ )
Next, Betsimas-Lo extended the Linear Permanent Impact model
To include dependence on Serially-Correlated Variable $X_t$
$$
P_{t+1}=P_t-\left(\beta N_t+\theta X_t\right)+\epsilon_t, X_{t+1}=\rho X_t+\eta_t, Q_t=P_t-\left(\beta N_t+\theta X_t\right)
$$
$\epsilon_t$ and $\eta_t$ are i.i.d. (and mutually independent) with mean zero
$X_t$ can be thought of as market factor affecting $P_t$ linearly
Bellman Equation on Optimal VF and same approach as before yields:
$$
\begin{gathered}
N_t^*=\frac{R_t}{T-t}+h(t, \beta, \theta, \rho) X_t \\
V_t^*\left(\left(P_t, R_t, X_t\right)\right)=R_t P_t-\left(\text { quadratic in }\left(R_t, X_t\right)+\text { constant }\right)
\end{gathered}
$$
Seral-correlation predictability $(\rho \neq 0)$ alters uniform-split strategy

\paragraph*{Improved Model (LPT Model - Bertismas-Lo)}
Bertsimas-Lo present a more realistic model called "LPT" Linear-Percentage Temporary Price Impact model features:
- Geometric random walk: consistent with real data, \& avoids prices $\leq 0$
- \% Price Impact $\frac{g_t\left(P_t, N_t\right)}{P_t}$ doesn't depend on $P_t$ (validated by real data)
- Purely Temporary Price Impact
$$
P_{t+1}=P_t e^{Z_t}, X_{t+1}=\rho X_t+\eta_t, Q_t=P_t\left(1-\beta N_t-\theta X_t\right)
$$
$Z_t$ is a random variable with mean $\mu_Z$ and variance $\sigma_Z^2$
With the same derivation as before, we get the solution:
$$
\begin{gathered}
N_t^*=c_t^{(1)}+c_t^{(2)} R_t+c_t^{(3)} X_t \\
V_t^*\left(\left(P_t, R_t, X_t\right)\right)=e^{\mu_Z+\frac{\sigma_Z^2}{2}} \cdot P_t \cdot\left(c_t^{(4)}+c_t^{(5)} R_t+c_t^{(6)} X_t\right. \\
\left.+c_t^{(7)} R_t^2+c_t^{(8)} X_t^2+c_t^{(9)} R_t X_t\right)
\end{gathered}
$$




\end{document}