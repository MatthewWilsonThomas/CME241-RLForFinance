{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TD($\\lambda$) prediction algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Iterator, TypeVar, List, Sequence, Mapping\n",
    "from rl.function_approx import Gradient\n",
    "import rl.markov_process as mp\n",
    "from rl.markov_decision_process import NonTerminal\n",
    "import numpy as np\n",
    "from rl.approximate_dynamic_programming import ValueFunctionApprox\n",
    "from rl.approximate_dynamic_programming import extended_vf\n",
    "\n",
    "S = TypeVar('S')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabular Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def td_lambda_prediction_tab(\n",
    "        traces: Iterable[Iterable[mp.TransitionStep[S]]],\n",
    "        gamma: float,\n",
    "        lambd: float,\n",
    "        alpha: float\n",
    ") -> Iterator[Mapping[S, float]]:\n",
    "    \n",
    "    vf: Mapping[S, float] = dict() # State VF approximation\n",
    "\n",
    "    yield vf\n",
    "    for trace in traces:\n",
    "        el_tr: Mapping[S, float] = dict() # Eligibility trace\n",
    "\n",
    "        trace_seq: Sequence[mp.TransitionStep[S]] = list(trace)\n",
    "        for t, step in enumerate(trace_seq):\n",
    "            x: NonTerminal[S] = step.state\n",
    "            el_tr[x.state] = lambd * gamma * el_tr.get(x.state, 0) + 1\n",
    "            y: float = step.reward + gamma * vf.get(step.next_state.state, 0) - vf.get(x.state, 0)\n",
    "            for state in vf.keys():\n",
    "                vf[state] = vf.get(state, 0) + alpha * y * el_tr.get(state, 0)\n",
    "\n",
    "            yield vf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function Approximation Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def td_lambda_prediction_func_approx(\n",
    "        traces: Iterable[Iterable[mp.TransitionStep[S]]],\n",
    "        approx_0: ValueFunctionApprox[S],\n",
    "        γ: float,\n",
    "        lambd: float\n",
    ") -> Iterator[ValueFunctionApprox[S]]:\n",
    "    func_approx: ValueFunctionApprox[S] = approx_0\n",
    "    yield func_approx\n",
    "\n",
    "    for trace in traces:\n",
    "        el_tr: Gradient[ValueFunctionApprox[S]] = Gradient(func_approx).zero()\n",
    "        for step in trace:\n",
    "            x: NonTerminal[S] = step.state\n",
    "            y: float = step.reward + γ * \\\n",
    "                extended_vf(func_approx, step.next_state)\n",
    "            el_tr = el_tr * (γ * lambd) + func_approx.objective_gradient(\n",
    "                xy_vals_seq=[(x, y)],\n",
    "                obj_deriv_out_fun=lambda x1, y1: np.ones(len(x1))\n",
    "            )\n",
    "            func_approx = func_approx.update_with_gradient(\n",
    "                el_tr * (func_approx(x) - y)\n",
    "            )\n",
    "            yield func_approx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CME241",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
