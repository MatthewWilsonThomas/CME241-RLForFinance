{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b097fbb8",
   "metadata": {},
   "source": [
    "# Learning to make a market with mbt_gym and Stable Baselines 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b918608",
   "metadata": {},
   "source": [
    "### Import external modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56ffdffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecMonitor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d0a2c9",
   "metadata": {},
   "source": [
    "### Add mbt-gym to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "387934ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cb89dbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mbt_gym'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0788fba474eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmbt_gym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaselineAgents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCarteaJaimungalAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmbt_gym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_trajectory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenerate_trajectory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmbt_gym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStableBaselinesTradingEnvironment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStableBaselinesTradingEnvironment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmbt_gym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTradingEnvironment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTradingEnvironment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmbt_gym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mbt_gym'"
     ]
    }
   ],
   "source": [
    "from mbt_gym.agents.BaselineAgents import CarteaJaimungalAgent\n",
    "from mbt_gym.gym.helpers.generate_trajectory import generate_trajectory\n",
    "from mbt_gym.gym.StableBaselinesTradingEnvironment import StableBaselinesTradingEnvironment\n",
    "from mbt_gym.gym.TradingEnvironment import TradingEnvironment\n",
    "from mbt_gym.gym.wrappers import *\n",
    "from mbt_gym.rewards.RewardFunctions import PnL, CjCriterion\n",
    "from mbt_gym.stochastic_processes.midprice_models import *\n",
    "from mbt_gym.stochastic_processes.fill_probability_models import *\n",
    "from mbt_gym.stochastic_processes.arrival_models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535d65b0",
   "metadata": {},
   "source": [
    "### Create market making environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98ab1846",
   "metadata": {},
   "outputs": [],
   "source": [
    "terminal_time = 1.0\n",
    "arrival_rate = 10.0\n",
    "n_steps = int(10 * terminal_time * arrival_rate)\n",
    "phi = 0.5\n",
    "alpha = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aa98a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cj_env(num_trajectories:int = 1):    \n",
    "    fill_exponent = 1\n",
    "    sigma = 0.1\n",
    "    initial_inventory = (-4,5)\n",
    "    initial_price = 100\n",
    "    step_size = 1/n_steps\n",
    "    timestamps = np.linspace(0, terminal_time, n_steps + 1)\n",
    "    env_params = dict(terminal_time=terminal_time, \n",
    "                      n_steps=n_steps,\n",
    "                      initial_inventory = initial_inventory,\n",
    "                      midprice_model = BrownianMotionMidpriceModel(volatility=sigma, \n",
    "                                                                   terminal_time=terminal_time, \n",
    "                                                                   step_size=step_size, \n",
    "                                                                   initial_price=initial_price, \n",
    "                                                                   num_trajectories=num_trajectories),\n",
    "                      arrival_model = PoissonArrivalModel(intensity=np.array([arrival_rate,arrival_rate]), \n",
    "                                                           step_size=step_size, \n",
    "                                                          num_trajectories=num_trajectories),\n",
    "                      fill_probability_model = ExponentialFillFunction(fill_exponent=fill_exponent, \n",
    "                                                                       step_size=step_size, \n",
    "                                                                       num_trajectories=num_trajectories),\n",
    "                      reward_function = CjCriterion(phi, alpha),\n",
    "                      max_inventory=n_steps,\n",
    "                      num_trajectories=num_trajectories)\n",
    "    return TradingEnvironment(**env_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d29022e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ReduceStateSizeWrapper' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-360ef792a344>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_trajectories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReduceStateSizeWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_cj_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_trajectories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msb_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStableBaselinesTradingEnvironment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrading_env\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ReduceStateSizeWrapper' is not defined"
     ]
    }
   ],
   "source": [
    "num_trajectories = 1000\n",
    "env = ReduceStateSizeWrapper(get_cj_env(num_trajectories))\n",
    "sb_env = StableBaselinesTradingEnvironment(trading_env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f837dc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VecMonitor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-717cf52d41df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Monitor sb_env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msb_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVecMonitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msb_env\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Add directory for tensorboard logging and best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtensorboard_logdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./tensorboard/PPO-learning-CJ/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbest_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./SB_models/PPO-best-CJ\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'VecMonitor' is not defined"
     ]
    }
   ],
   "source": [
    "# Monitor sb_env\n",
    "sb_env = VecMonitor(sb_env)\n",
    "# Add directory for tensorboard logging and best model\n",
    "tensorboard_logdir = \"./tensorboard/PPO-learning-CJ/\"\n",
    "best_model_path = \"./SB_models/PPO-best-CJ\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3106df91",
   "metadata": {},
   "source": [
    "### Define PPO policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5d0e1c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sb_env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ed591dd9d63f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpolicy_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_arch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m PPO_params = {\"policy\":'MlpPolicy', \"env\": sb_env, \"verbose\":1, \n\u001b[0m\u001b[1;32m      3\u001b[0m               \u001b[0;34m\"policy_kwargs\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpolicy_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               \u001b[0;34m\"tensorboard_log\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtensorboard_logdir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m               \u001b[0;34m\"n_epochs\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sb_env' is not defined"
     ]
    }
   ],
   "source": [
    "policy_kwargs = dict(net_arch=[dict(pi=[256, 256], vf=[256, 256])])\n",
    "PPO_params = {\"policy\":'MlpPolicy', \"env\": sb_env, \"verbose\":1, \n",
    "              \"policy_kwargs\":policy_kwargs, \n",
    "              \"tensorboard_log\":tensorboard_logdir,\n",
    "              \"n_epochs\":3,\n",
    "              \"batch_size\": int(n_steps * num_trajectories / 10), \n",
    "              \"n_steps\": int(n_steps)}\n",
    "callback_params = dict(eval_env=sb_env, n_eval_episodes = 2048, #200 before  (n_eval_episodes)\n",
    "                       best_model_save_path = best_model_path, \n",
    "                       deterministic=True)\n",
    "\n",
    "callback = EvalCallback(**callback_params)\n",
    "model = PPO(**PPO_params, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01707612",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-083d2eb568f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10_000_000\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Increase number of training timesteps according to computing resources\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps = 10_000_000)  # Increase number of training timesteps according to computing resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d74b6cd",
   "metadata": {},
   "source": [
    "## Comparing the learnt policy to the optimal policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc4d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbt_gym.agents.SbAgent import SbAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b78c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_agent = SbAgent(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcb28e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventories = np.arange(-3,4,1)\n",
    "bid_actions = []\n",
    "ask_actions = []\n",
    "for inventory in inventories:\n",
    "    bid_action, ask_action = ppo_agent.get_action(np.array([[inventory,0.5]]))\n",
    "    bid_actions.append(bid_action)\n",
    "    ask_actions.append(ask_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6bb5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cj_agent = CarteaJaimungalAgent(phi = phi, alpha= alpha, env=get_cj_env())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a344c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Cartea Jaimungal action\n",
    "cj_bid_actions = []\n",
    "cj_ask_actions = []\n",
    "for inventory in inventories:\n",
    "    bid_action, ask_action = cj_agent.get_action(np.array([[0,inventory,0.5]])).reshape(-1)\n",
    "    cj_bid_actions.append(bid_action)\n",
    "    cj_ask_actions.append(ask_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615c8e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(inventories, bid_actions, label = \"bid\", color = \"k\")\n",
    "plt.plot(inventories, ask_actions, label = \"ask\", color = \"r\")\n",
    "plt.plot(inventories, cj_bid_actions, label = \"bid cj\", color = \"k\", linestyle = \"--\")\n",
    "plt.plot(inventories, cj_ask_actions, label = \"ask cj\", color = \"r\", linestyle = \"--\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f1203e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
